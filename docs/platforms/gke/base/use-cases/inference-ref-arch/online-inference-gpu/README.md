# Online inference with GPUs on Google Kubernetes Engine (GKE)

These examples implement online inference with GPUs on Google Kubernetes Engine
(GKE) using the
[GKE Inference reference implementation](/platforms/gke/base/use-cases/inference-ref-arch/terraform/README.md).

- [Online inference using Diffusers with GPUs on Google Kubernetes Engine (GKE)](/docs/platforms/gke/base/use-cases/inference-ref-arch/online-inference-gpu/diffusers-with-hf-model.md)
- [Online inference using vLLM with GPUs on Google Kubernetes Engine (GKE)](/docs/platforms/gke/base/use-cases/inference-ref-arch/online-inference-gpu/vllm-with-hf-model.md)
