# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
apiVersion: batch/v1
kind: Job
metadata:
  name: finetune-gemma-h100
spec:
  backoffLimit: 0
  completions: 1
  parallelism: 1
  completionMode: Indexed
  template:
    metadata:
      labels:
        app: finetune-job
        ml-platform: fine-tuning
      annotations:
        gke-gcsfuse/volumes: "true"
        gke-gcsfuse/memory-limit: "35Gi"
    spec:
      containers:
        - name: gpu-job
          imagePullPolicy: Always
          image: ${mft_fine_tuning_image_url}
          ports:
            - containerPort: 29500
          securityContext:
            privileged: true
          resources:
            requests:
              nvidia.com/gpu: "8"
            limits:
              nvidia.com/gpu: "8"
          command:
            - bash
            - -c
            - |
              accelerate launch \
              --config_file fsdp_config.yaml \
              --debug \
              --main_process_ip finetune-gemma-h100-0.headless-svc-h100 \
              --main_process_port 29500 \
              --machine_rank $(JOB_COMPLETION_INDEX) \
              --num_processes 8 \
              --num_machines 1 \
              fine_tune.py
          env:
            - name: "EXPERIMENT"
              value: finetune-experiment
            - name: HF_TOKEN_PATH
              value: /var/run/secrets/huggingface.co/token
            - name: "MLFLOW_ENABLE"
              value: "true"
            - name: "MLFLOW_TRACKING_URI"
              value: "http://mlflow-tracking-svc:5000"
            - name: "MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING"
              value: "true"
            - name: "TRAINING_DATASET_BUCKET"
              value: ${mft_data_bucket_name}
            - name: "TRAINING_DATASET_PATH"
              value: dataset/output/training
            - name: MODEL_NAME
              value: google/gemma-2-9b-it
            - name: NCCL_DEBUG
              value: "INFO"
            - name: NEW_MODEL
              value: "gemma-ft"
            - name: MODEL_PATH
              value: "/model-data/model-gemma2/experiment"
            - name: EPOCHS
              value: "1"
            - name: TRAIN_BATCH_SIZE
              value: "1"
          volumeMounts:
            - mountPath: /dev/shm
              name: dshm
            - mountPath: /model-data
              name: gcs-fuse-csi-ephemeral
              readOnly: false
            - mountPath: /var/run/secrets/huggingface.co
              name: huggingface-token
      nodeSelector:
        cloud.google.com/compute-class: gpu-h100-80gb-high-x2
      restartPolicy: OnFailure
      serviceAccountName: ${mft_fine_tuning_service_account_name}
      subdomain: headless-svc-h100
      terminationGracePeriodSeconds: 600
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        - csi:
            driver: gcsfuse.csi.storage.gke.io
            volumeAttributes:
              bucketName: ${mft_bucket_model_name}
              mountOptions: "implicit-dirs"
              gcsfuseLoggingSeverity: warning
          name: gcs-fuse-csi-ephemeral
        - csi:
            driver: secrets-store-gke.csi.k8s.io
            readOnly: true
            volumeAttributes:
              secretProviderClass: huggingface-token-read
          name: huggingface-token
---
apiVersion: v1
kind: Service
metadata:
  name: headless-svc-h100
spec:
  clusterIP: None
  selector:
    job-name: finetune-gemma-h100
