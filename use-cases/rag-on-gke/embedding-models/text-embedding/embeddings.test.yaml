#gcloud container node-pools create embeddings-pool --cluster $CLUSTER_NAME 
#--accelerator type=nvidia-tesla-t4,count=1,gpu-driver-version=latest   --machine-type n1-standard-4 --ephemeral-storage-local-ssd=count=1   --enable-autoscaling --enable-image-streaming   --num-nodes=1 --min-nodes=0 --max-nodes=3 --shielded-secure-boot   --shielded-integrity-monitoring --node-version=1.29 --node-locations us-east1-c --region us-east1 --spot

apiVersion: apps/v1
kind: Deployment
metadata:
  name: text-embedding-model-deployment
  namespace: text-embedding-model # namespace
spec:
  selector:
    matchLabels:
      app: embedding-serve
  template:
    metadata:
      labels:
        app: embedding-serve
    spec:
      volumes:
       - name: data
         emptyDir: {}
       - name: dshm
         emptyDir:
              medium: Memory
      # tolerations:
      # - key: "nvidia.com/gpu"
      #   operator: "Equal"
      #   value: "present"
      #   effect: "NoSchedule"
      # - key: "on-demand"
      #   operator: "Equal"
      #   value: "true"
      #   effect: "NoSchedule"
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Equal"
        value: "present"
        effect: "NoSchedule"
      - key: "cloud.google.com/gke-queued"
        value: "true"
        operator: "Equal"
        effect: "NoSchedule"
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4
        pool-type: l4-2-sb
      containers:
      - name: embeddings
        image: us-docker.pkg.dev/gkebatchenv3a4ec43f/rag-artifacts/sentence-transformer:latest #replace with your sentence transformer image path
        resources:
            limits:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "1"
            requests:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "1"
        env:
            - name: model_name
              value: Alibaba-NLP/gte-large-en-v1.5            
            - name: shm-size
              value: 1g
        ports:
        - containerPort: 5000
        volumeMounts:
            - mountPath: /dev/shm
              name: dshm
            - mountPath: /data
              name: data
---
apiVersion: v1
kind: Service
metadata:
  name: embedding-serve
  namespace: text-embedding-model # namespace 
spec:
  type: LoadBalancer
  selector:
    app: embedding-serve
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 5000
