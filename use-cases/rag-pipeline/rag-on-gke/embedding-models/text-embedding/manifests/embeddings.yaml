apiVersion: apps/v1
kind: Deployment
metadata:
  name: text-embedding-model-deployment
  namespace: text-embedding-model # namespace
spec:
  selector:
    matchLabels:
      app: embedding-serve
  template:
    metadata:
      labels:
        app: embedding-serve
    spec:
      volumes:
       - name: data
         emptyDir: {}
       - name: dshm
         emptyDir:
              medium: Memory
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4      
        cloud.google.com/gke-nodepool: gpu-l4x2-g2s24        
      tolerations:
       - key: "nvidia.com/gpu"
         operator: "Equal"
         value: "present"
         effect: "NoSchedule"
       - key: "on-demand"
         operator: "Equal"
         value: "true"
         effect: "NoSchedule"
      containers:
      - name: embeddings
        image: us-docker.pkg.dev/gkebatchenv3a4ec43f/rag-artifacts/sentence-transformer:latest #replace with your sentence transformer image path
        resources:
            limits:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "2"
            requests:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "2"
        env:
            - name: model_name
              value: Alibaba-NLP/gte-large-en-v1.5            
            - name: shm-size
              value: 1g
        ports:
        - containerPort: 5000
        volumeMounts:
            - mountPath: /dev/shm
              name: dshm
            - mountPath: /data
              name: data
---
apiVersion: v1
kind: Service
metadata:
  name: embedding-serve
  namespace: text-embedding-model # namespace 
spec:
  type: LoadBalancer
  selector:
    app: embedding-serve
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 5000
